# ğŸ‘‹ Hi, Iâ€™m Carolina

Iâ€™m an aspiring AI engineer with a strong interest in **large language models (LLMs)**, **retrieval-augmented generation (RAG)**, and **trustworthy AI systems**. I enjoy building applied ML projects that sit at the intersection of theory and real-world impact, especially around transparency, reliability, and human-centered AI.

Iâ€™m particularly interested in:
- Large language models and prompt engineering  
- Retrieval-augmented generation (RAG) systems  
- Reducing hallucinations and improving model reliability  
- Model evaluation, interpretability, and responsible AI  
- Applied ML systems and MLOps workflows  

This GitHub serves as a space to document my learning, experiments, and end-to-end projects as I work toward becoming an AI engineer.

---

## Current Projects

### ğŸ“š Semantic Book Recommender
A recommendation system that goes beyond keyword matching by leveraging **semantic embeddings** to understand user intent and content similarity.

**Key ideas & features:**
- Uses embedding-based similarity to recommend books by meaning, not just keywords  
- Supports flexible, natural-language user queries  
- Focuses on explainability (why a book was recommended)  
- Designed as a modular ML pipeline (data â†’ embeddings â†’ retrieval â†’ ranking)

This project explores how representation learning can improve traditional recommender systems while remaining interpretable and user-focused.

---

### ğŸ¤– Retrieval-Augmented Generation (RAG) Chatbot
An end-to-end RAG chatbot designed to answer questions grounded in a specific document corpus rather than relying solely on model memory.

**Key ideas & features:**
- Document ingestion, chunking, and vector storage  
- Semantic retrieval to surface relevant context  
- LLM-based answer generation constrained by retrieved sources  
- Explicit handling of â€œI donâ€™t knowâ€ cases to reduce hallucinations  
- Emphasis on evaluation, citation, and reliability

This project reflects my interest in **trustworthy LLM applications**, particularly in how retrieval, prompting, and evaluation can be combined to improve factual accuracy.

---

## What Iâ€™m Exploring Next
- Hallucination detection and confidence scoring for LLM outputs  
- Model interpretability dashboards for ML/LLM systems  
- MLOps practices for deploying and monitoring AI applications  
- AI applications in high-stakes domains (e.g., healthcare, education)

---

## Letâ€™s Connect
If youâ€™re interested in AI systems, LLM applications, or responsible ML, feel free to explore my repositories or reach out. Iâ€™m always excited to learn, collaborate, and get feedback.

Thanks for stopping by!


